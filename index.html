<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>KiddoBot - Your Friendly Talking Buddy</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Nunito:wght@400;600;700&family=Comic+Neue:wght@400;700&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Comic Neue', cursive;
            background-color: #f8f1e9;
            background-image: url("data:image/svg+xml,%3Csvg width='60' height='60' viewBox='0 0 60 60' xmlns='http://www.w3.org/2000/svg'%3E%3Cg fill='none' fill-rule='evenodd'%3E%3Cg fill='%23e2d3c2' fill-opacity='0.4'%3E%3Cpath d='M36 34v-4h-2v4h-4v2h4v4h2v-4h4v-2h-4zm0-30V0h-2v4h-4v2h4v4h2V6h4V4h-4zM6 34v-4H4v4H0v2h4v4h2v-4h4v-2H6zM6 4V0H4v4H0v2h4v4h2V6h4V4H6z'/%3E%3C/g%3E%3C/g%3E%3C/svg%3E");
        }
        
        .chat-container {
            max-width: 800px;
            margin: auto;
            border-radius: 1.5rem;
            box-shadow: 0 10px 25px -5px rgba(101, 67, 33, 0.2), 0 8px 10px -6px rgba(101, 67, 33, 0.1);
            background-color: #fffaf5;
            border: 8px solid #8b5a2b;
            overflow: hidden;
        }
        
        .header {
            background-color: #8b5a2b;
            color: #fff8e1;
            padding: 1rem;
            text-align: center;
            font-family: 'Nunito', sans-serif;
            font-weight: 700;
            font-size: 1.75rem;
            border-bottom: 4px dashed #654321;
        }
        
        .message-bubble {
            border-radius: 1.25rem;
            padding: 0.75rem 1.25rem;
            margin-bottom: 0.75rem;
            display: inline-block;
            max-width: 80%;
            clear: both;
            position: relative;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }
        
        .user-message {
            background-color: #e6c9a8;
            color: #4b2e0e;
            float: right;
            border-top-right-radius: 0.25rem;
            margin-right: 10px;
        }
        
        .user-message:after {
            content: "";
            position: absolute;
            right: -10px;
            top: 0;
            border: 10px solid transparent;
            border-top-color: #e6c9a8;
            border-right: 0;
        }
        
        .agent-message {
            background-color: #a67c52;
            color: #fff8e1;
            float: left;
            border-top-left-radius: 0.25rem;
            margin-left: 10px;
        }
        
        .agent-message:after {
            content: "";
            position: absolute;
            left: -10px;
            top: 0;
            border: 10px solid transparent;
            border-top-color: #a67c52;
            border-left: 0;
        }
        
        .input-area {
            display: flex;
            align-items: center;
            padding: 1rem;
            background-color: #d7bc9d;
            border-top: 4px dashed #8b5a2b;
        }
        
        .text-input {
            flex: 1;
            border-radius: 1.25rem;
            padding: 0.75rem 1.25rem;
            border: 3px solid #8b5a2b;
            background-color: #fff8e1;
            color: #4b2e0e;
            margin-right: 0.75rem;
            font-size: 1.1rem;
            transition: all 0.3s ease;
        }
        
        .text-input:focus {
            outline: none;
            border-color: #654321;
            box-shadow: 0 0 0 4px rgba(139, 90, 43, 0.3);
            transform: scale(1.01);
        }
        
        .text-input::placeholder {
            color: #bc8a5f;
        }
        
        .send-button {
            border-radius: 1.25rem;
            padding: 0.75rem 1.5rem;
            background-color: #8b5a2b;
            color: #fff8e1;
            border: none;
            font-weight: 700;
            cursor: pointer;
            transition: all 0.3s ease;
            font-size: 1.1rem;
        }
        
        .send-button:hover {
            background-color: #654321;
            transform: scale(1.05);
        }
        
        .send-button:disabled {
            background-color: #d7bc9d;
            cursor: not-allowed;
            transform: none;
        }
        
        #audio-visualizer {
            width: 100%;
            height: 40px;
            margin-top: 0.5rem;
            margin-bottom: 0.5rem;
            border-radius: 1rem;
            background-color: #e6c9a8;
            display: none;
            position: relative;
            overflow: hidden;
        }
        
        .recording-animation {
            border: 4px solid #8b5a2b;
            animation: pulse 2s infinite, colorChange 4s infinite alternate;
        }
        
        @keyframes pulse {
            0% { transform: scale(1); }
            50% { transform: scale(1.02); }
            100% { transform: scale(1); }
        }
        
        @keyframes colorChange {
            0% { background-color: #e6c9a8; }
            50% { background-color: #d7bc9d; }
            100% { background-color: #e6c9a8; }
        }
        
        .robot-avatar {
            width: 80px;
            height: 80px;
            background-color: #8b5a2b;
            border-radius: 50%;
            margin: 1rem auto;
            position: relative;
            box-shadow: 0 4px 8px rgba(0,0,0,0.2);
            border: 4px solid #654321;
        }
        
        .robot-eye {
            position: absolute;
            width: 20px;
            height: 20px;
            background-color: #fff8e1;
            border-radius: 50%;
            top: 20px;
        }
        
        .robot-eye:after {
            content: "";
            position: absolute;
            width: 10px;
            height: 10px;
            background-color: #4b2e0e;
            border-radius: 50%;
            top: 5px;
            left: 5px;
        }
        
        .robot-eye.left {
            left: 15px;
        }
        
        .robot-eye.right {
            right: 15px;
        }
        
        .robot-mouth {
            position: absolute;
            width: 40px;
            height: 10px;
            background-color: #fff8e1;
            border-radius: 5px;
            bottom: 15px;
            left: 50%;
            transform: translateX(-50%);
        }
        
        .chat-messages {
            padding: 1rem;
            overflow-y: auto;
            height: calc(100vh - 250px);
            min-height: 300px;
            background-color: #fffaf5;
        }
        
        .status-indicator {
            font-size: 0.9rem;
            text-align: center;
            color: #a67c52;
            margin: 0.5rem 0;
            font-style: italic;
        }
        
        .time-stamp {
            font-size: 0.7rem;
            opacity: 0.7;
            margin-top: 4px;
            display: block;
        }
        
        .clearfix::after {
            content: "";
            clear: both;
            display: table;
        }
        
        .voice-controls {
            display: flex;
            justify-content: center;
            padding: 0.5rem;
            gap: 1rem;
        }
        
        .toggle-button {
            background-color: #8b5a2b;
            color: #fff8e1;
            border: none;
            border-radius: 1rem;
            padding: 0.5rem 1rem;
            font-size: 0.9rem;
            cursor: pointer;
            transition: all 0.3s ease;
        }
        
        .toggle-button:hover {
            background-color: #654321;
            transform: scale(1.05);
        }
        
        .toggle-button.active {
            background-color: #4b2e0e;
            box-shadow: inset 0 0 5px rgba(0,0,0,0.5);
        }
    </style>
</head>
<body class="min-h-screen">
    <div class="py-8 px-4">
        <div class="chat-container">
            <div class="header">
                KiddoBot - Your Talking Friend
            </div>
            
            <div class="robot-avatar">
                <div class="robot-eye left"></div>
                <div class="robot-eye right"></div>
                <div class="robot-mouth"></div>
            </div>
            
            <div class="voice-controls">
                <button id="toggle-voice" class="toggle-button active">Voice On</button>
                <button id="stop-speaking" class="toggle-button">Stop Speaking</button>
                <button id="restart-voice" class="toggle-button">Restart Voice</button>
            </div>
            
            <div class="chat-messages" id="chat-messages">
                <!-- Messages will appear here -->
            </div>
            
            <div id="status" class="status-indicator"></div>
            <div id="audio-visualizer"></div>
            
            <div class="input-area">
                <input type="text" id="text-input" class="text-input" placeholder="Type your message..." disabled>
                <button id="send-button" class="send-button" disabled>Send</button>
            </div>
        </div>
    </div>

    <script>
        const chatMessages = document.getElementById('chat-messages');
        const textInput = document.getElementById('text-input');
        const sendButton = document.getElementById('send-button');
        const audioVisualizer = document.getElementById('audio-visualizer');
        const statusIndicator = document.getElementById('status');
        const robotMouth = document.querySelector('.robot-mouth');
        const toggleVoiceButton = document.getElementById('toggle-voice');
        const stopSpeakingButton = document.getElementById('stop-speaking');

        let isRecording = false;
        let mediaRecorder;
        let audioChunks = [];
        let speechRecognition;
        let previousResponse = "";
        let isSpeechEnabled = true;
        let speechSynthesis = window.speechSynthesis;
        let currentUtterance = null;

        // --- Speech Synthesis Functions (Text-to-Speech) ---
        
        /**
         * Speaks the given text using the Web Speech API.
         * @param {string} text - The text to speak.
         */
        function speakText(text) {
            if (!isSpeechEnabled) return;
            
            // Stop any current speech
            if (speechSynthesis.speaking) {
                speechSynthesis.cancel();
            }
            
            // Create a new speech utterance
            const utterance = new SpeechSynthesisUtterance(text);
            
            // Configure speech settings for a sweet lady voice
            utterance.rate = 0.95;     // Slightly slower speed for clarity
            utterance.pitch = 1.2;     // Higher pitch for female voice (0 to 2)
            utterance.volume = 0.9;    // Good volume level (0 to 1)
            
            // Get available voices
            const voices = speechSynthesis.getVoices();
            console.log("Available voices:", voices.map(v => `${v.name} (${v.lang})`));
            
            // Prioritize American female voices (in order of preference)
            const preferredVoiceNames = [
                'Samantha',           // iOS/macOS (American female)
                'Google US English',  // Chrome (American female)
                'Microsoft Zira',     // Windows (American female)
                'Karen',              // macOS (Australian but sweet)
                'Victoria',           // macOS/iOS (American female)
                'Siri Female',        // Some browsers (American female)
                'en-US-Standard-F',   // Some browsers (American female)
                'en-US-Standard-E'    // Some browsers (American female)
            ];
            
            // First try to find American English female voices
            let preferredVoices = voices.filter(voice => 
                (voice.lang === 'en-US' || voice.lang.startsWith('en-US')) && 
                (preferredVoiceNames.some(name => voice.name.includes(name)) ||
                 voice.name.toLowerCase().includes('female') ||
                 voice.name.toLowerCase().includes('woman'))
            );
            
            // If no American voices found, try any English female voices
            if (preferredVoices.length === 0) {
                preferredVoices = voices.filter(voice => 
                    voice.lang.startsWith('en') && 
                    (preferredVoiceNames.some(name => voice.name.includes(name)) ||
                     voice.name.toLowerCase().includes('female') ||
                     voice.name.toLowerCase().includes('woman'))
                );
            }
            
            // If still no luck, try these specific voice names
            if (preferredVoices.length === 0) {
                preferredVoices = voices.filter(voice => 
                    preferredVoiceNames.some(name => voice.name.includes(name))
                );
            }
            
            // If we found a preferred voice, use it
            if (preferredVoices.length > 0) {
                utterance.voice = preferredVoices[0];
                console.log("Selected voice:", preferredVoices[0].name);
            } else {
                // Fallback: find any voice that seems American and female
                const fallbackVoices = voices.filter(voice => 
                    voice.lang === 'en-US' || voice.lang.startsWith('en-US')
                );
                if (fallbackVoices.length > 0) {
                    utterance.voice = fallbackVoices[0];
                    console.log("Fallback voice:", fallbackVoices[0].name);
                }
            }
            
            // Track current utterance
            currentUtterance = utterance;
            
            // Event handlers
            utterance.onstart = () => {
                const talkingInterval = animateMouth(true);
                utterance._mouthAnimation = talkingInterval;
            };
            
            utterance.onend = () => {
                if (utterance._mouthAnimation) {
                    clearInterval(utterance._mouthAnimation);
                }
                animateMouth(false);
                
                // Resume speech recognition after speaking if needed
                if (speechRecognition) {
                    setTimeout(() => {
                        startSpeechRecognition();
                    }, 500);
                }
            };
            
            utterance.onerror = (event) => {
                console.error("Speech synthesis error:", event);
                if (utterance._mouthAnimation) {
                    clearInterval(utterance._mouthAnimation);
                }
                animateMouth(false);
            };
            
            // Start speaking
            speechSynthesis.speak(utterance);
        }

        // --- Robot Animation Functions ---
        function animateMouth(speaking) {
            if (speaking) {
                // Simulate talking
                robotMouth.style.transition = 'height 0.1s ease-in-out';
                let talkingInterval = setInterval(() => {
                    const height = Math.floor(Math.random() * 15) + 5;
                    robotMouth.style.height = `${height}px`;
                }, 150);
                
                return talkingInterval;
            } else {
                robotMouth.style.height = '10px';
                robotMouth.style.transition = 'height 0.3s ease';
            }
        }

        // --- Helper Functions ---
        function getCurrentTime() {
            const now = new Date();
            let hours = now.getHours();
            const minutes = now.getMinutes().toString().padStart(2, '0');
            const ampm = hours >= 12 ? 'PM' : 'AM';
            hours = hours % 12;
            hours = hours ? hours : 12; // Convert 0 to 12
            return `${hours}:${minutes} ${ampm}`;
        }

        /**
         * Adds a message to the chat interface.
         * @param {string} message - The text of the message.
         * @param {string} sender - "user" or "agent".
         */
        function addMessage(message, sender) {
            const messageElement = document.createElement('div');
            messageElement.classList.add('message-bubble', `${sender}-message`);
            
            // Main message text
            const messageText = document.createElement('div');
            messageText.textContent = message;
            messageElement.appendChild(messageText);
            
            // Add timestamp
            const timeStamp = document.createElement('span');
            timeStamp.classList.add('time-stamp');
            timeStamp.textContent = getCurrentTime();
            messageElement.appendChild(timeStamp);
            
            // Add to chat container with a clearfix
            const clearfix = document.createElement('div');
            clearfix.classList.add('clearfix');
            chatMessages.appendChild(messageElement);
            chatMessages.appendChild(clearfix);
            
            // Scroll to bottom
            chatMessages.scrollTop = chatMessages.scrollHeight;
            
            // If it's the agent speaking and speech is enabled, use text-to-speech
            if (sender === 'agent') {
                if (speechRecognition && speechRecognition.state === 'active') {
                    stopSpeechRecognition();
                }
                
                speakText(message);
            }
        }

        /**
         * Handles the agent's response using a direct API call.
         * @param {string} userInput - The user's input.
         */
        async function agentResponse(userInput) {
            statusIndicator.textContent = "KiddoBot is thinking...";
            let response = "";
            
            try {
                // Direct API call to Gemini API
                const apiKey = 'AIzaSyBsCGn5ykZS3vDukZm6PQbzl9oh49BVScY'; // Replace with your actual API key in production
                const apiUrl = `https://generativelanguage.googleapis.com/v1/models/gemini-1.5-pro:generateContent?key=${apiKey}`;
                
                // Create the request payload
                const requestData = {
                    contents: [{
                        parts: [{
                            text: `You are KiddoBot, a friendly AI assistant for children aged 5-12. 
                            Use simple language, be enthusiastic, patient, educational and always kid-friendly. 
                            Keep responses concise (2-4 sentences max) and use analogies children understand.
                            User message: "${userInput}"`
                        }]
                    }]
                };
                
                console.log("Sending request to API...");
                
                // Make the API request
                const apiResponse = await fetch(apiUrl, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify(requestData)
                });
                
                if (!apiResponse.ok) {
                    const errorText = await apiResponse.text();
                    console.error(`API error (${apiResponse.status}):`, errorText);
                    throw new Error(`API request failed with status: ${apiResponse.status}`);
                }
                
                // Parse the response
                const data = await apiResponse.json();
                console.log("API response:", data);
                
                // Extract the text from the response
                if (data && data.candidates && data.candidates[0]?.content?.parts && data.candidates[0].content.parts.length > 0) {
                    response = data.candidates[0].content.parts[0].text;
                    // Make sure the response is appropriate for kids
                    response = makeKidFriendly(response);
                } else {
                    console.error("Response doesn't match expected structure:", data);
                    response = "I'm not sure what to say about that. Can you ask me something else?";
                }
            } catch (error) {
                console.error("Error fetching or processing API response:", error);
                response = "I'm having a little trouble thinking right now. Can you ask me again?";
            }

            // Display the response with a slight delay
            setTimeout(() => {
                statusIndicator.textContent = "";
                addMessage(response, 'agent');
                previousResponse = response;
            }, 1000);
        }

        /**
         * Makes API responses kid-friendly.
         */
        function makeKidFriendly(text) {
            text = text.replace(/adult/gi, "grown-up");
            text = text.replace(/complicated/gi, "tricky");
            text = text.replace(/difficult/gi, "challenging");
            text = text.replace(/explain/gi, "tell me about");
            text = text.replace(/uncertain/gi, "not sure");
            text = text.replace(/unfortunate/gi, "not great");
            text = text.replace(/nevertheless/gi, "still");
            text = text.replace(/however/gi, "but");
            text = text.replace(/therefore/gi, "so");
            text = text.replace(/furthermore/gi, "also");
            return text;
        }

        // --- Speech Recognition Functions (Web Speech API) ---
        /**
         * Initializes and starts speech recognition.
         */
        function startSpeechRecognition() {
            // Check for standard and webkit implementations
            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            
            if (SpeechRecognition) {
                // Clean up any previous instance
                if (speechRecognition) {
                    try {
                        speechRecognition.stop();
                    } catch (e) {
                        console.log("Cleaning up previous recognition instance");
                    }
                }
                
                speechRecognition = new SpeechRecognition();
                
                // Configure for better recognition
                speechRecognition.continuous = true;       // Keep listening until manually stopped
                speechRecognition.lang = 'en-US';          // Set language
                speechRecognition.interimResults = true;   // Get results as they come in
                speechRecognition.maxAlternatives = 3;     // Get multiple interpretations
                
                let finalTranscript = '';
                let isProcessingResult = false;
                
                speechRecognition.onstart = () => {
                    isRecording = true;
                    sendButton.textContent = "Listening...";
                    sendButton.disabled = true;
                    textInput.disabled = true;
                    audioVisualizer.style.display = 'block';
                    audioVisualizer.classList.add('recording-animation');
                    statusIndicator.textContent = "I'm listening...";
                    finalTranscript = '';
                };

                speechRecognition.onresult = (event) => {
                    // Don't process new results if we're already processing one
                    if (isProcessingResult) return;
                    
                    let interimTranscript = '';
                    
                    // Process all results, adding confident final results to our transcript
                    for (let i = event.resultIndex; i < event.results.length; i++) {
                        const transcript = event.results[i][0].transcript;
                        
                        if (event.results[i].isFinal) {
                            finalTranscript += transcript + ' ';
                        } else {
                            interimTranscript += transcript;
                        }
                    }
                    
                    // Update status with interim results
                    if (interimTranscript) {
                        statusIndicator.textContent = `I heard: ${interimTranscript}`;
                    }
                    
                    // If we have a final transcript with reasonable length, process it
                    if (finalTranscript && finalTranscript.length > 2 && !isProcessingResult) {
                        // Prevent multiple processing of the same input
                        isProcessingResult = true;
                        
                        // Use the best transcript
                        const cleanTranscript = finalTranscript.trim();
                        console.log("Final transcript:", cleanTranscript);
                        
                        // Stop recognition while processing
                        speechRecognition.stop();
                        
                        // Process the message
                        addMessage(cleanTranscript, 'user');
                        agentResponse(cleanTranscript);
                        
                        // Reset
                        finalTranscript = '';
                        interimTranscript = '';
                    }
                };

                speechRecognition.onend = () => {
                    // Only reset if we weren't in the middle of processing a result
                    if (!isProcessingResult) {
                        isRecording = false;
                        sendButton.textContent = "Send";
                        sendButton.disabled = false;
                        textInput.disabled = false;
                        audioVisualizer.style.display = 'none';
                        audioVisualizer.classList.remove('recording-animation');
                        statusIndicator.textContent = "";
                        
                        // Restart automatically if not processing a result
                        // This makes the listening more continuous
                        try {
                            if (!speechSynthesis.speaking) {
                                setTimeout(() => {
                                    speechRecognition.start();
                                }, 1000);
                            }
                        } catch (e) {
                            console.error("Error restarting speech recognition:", e);
                        }
                    } else {
                        // If we were processing, this is an expected stop
                        isProcessingResult = false;
                    }
                };

                speechRecognition.onerror = (event) => {
                    console.error("Speech Recognition Error:", event.error);
                    
                    // Handle specific errors
                    if (event.error === 'no-speech') {
                        // No speech detected - this is common and not a problem
                        console.log("No speech detected");
                        statusIndicator.textContent = "I'm waiting for you to say something...";
                        setTimeout(() => statusIndicator.textContent = "", 2000);
                    } else if (event.error === 'aborted') {
                        // Recognition was aborted intentionally - not a problem
                        console.log("Recognition aborted");
                    } else {
                        // Other errors - reset UI
                        isRecording = false;
                        sendButton.textContent = "Send";
                        sendButton.disabled = false;
                        textInput.disabled = false;
                        audioVisualizer.style.display = 'none';
                        audioVisualizer.classList.remove('recording-animation');
                        statusIndicator.textContent = "I couldn't hear you properly. Please try again.";
                        setTimeout(() => {
                            statusIndicator.textContent = "";
                        }, 3000);
                    }
                };

                try {
                    speechRecognition.start();
                } catch (e) {
                    console.error("Error starting speech recognition:", e);
                    alert("There was an error starting speech recognition. Please reload the page.");
                    textInput.disabled = false;
                    sendButton.disabled = false;
                }
            } else {
                alert("Speech recognition is not supported in this browser.");
                textInput.disabled = false;
                sendButton.disabled = false;
                statusIndicator.textContent = "Voice chat isn't available in this browser. You can still type!";
            }
        }

        /**
         * Stops speech recognition.
         */
        function stopSpeechRecognition() {
            if (speechRecognition) {
                speechRecognition.stop();
                isRecording = false;
                sendButton.textContent = "Send";
                sendButton.disabled = false;
                textInput.disabled = false;
                audioVisualizer.style.display = 'none';
                audioVisualizer.classList.remove('recording-animation');
                statusIndicator.textContent = "";
            }
        }

        // --- Event Listeners ---

        // Toggle voice on/off
        toggleVoiceButton.addEventListener('click', () => {
            isSpeechEnabled = !isSpeechEnabled;
            toggleVoiceButton.textContent = isSpeechEnabled ? "Voice On" : "Voice Off";
            toggleVoiceButton.classList.toggle('active', isSpeechEnabled);
            
            if (!isSpeechEnabled && speechSynthesis.speaking) {
                speechSynthesis.cancel();
                if (currentUtterance && currentUtterance._mouthAnimation) {
                    clearInterval(currentUtterance._mouthAnimation);
                }
                animateMouth(false);
            }
        });

        // Stop speaking button
        stopSpeakingButton.addEventListener('click', () => {
            if (speechSynthesis.speaking) {
                speechSynthesis.cancel();
                if (currentUtterance && currentUtterance._mouthAnimation) {
                    clearInterval(currentUtterance._mouthAnimation);
                }
                animateMouth(false);
                
                // Resume speech recognition after cancelling speech
                if (speechRecognition) {
                    setTimeout(() => {
                        startSpeechRecognition();
                    }, 500);
                }
            }
        });
        
        // Restart voice recognition button
        document.getElementById('restart-voice').addEventListener('click', () => {
            // Stop any current speech and recognition
            if (speechSynthesis.speaking) {
                speechSynthesis.cancel();
                if (currentUtterance && currentUtterance._mouthAnimation) {
                    clearInterval(currentUtterance._mouthAnimation);
                }
                animateMouth(false);
            }
            
            if (speechRecognition) {
                try {
                    speechRecognition.stop();
                } catch (e) {
                    console.log("Error stopping speech recognition:", e);
                }
            }
            
            statusIndicator.textContent = "Restarting voice...";
            
            // Re-initialize the speech recognition after a short delay
            setTimeout(() => {
                startSpeechRecognition();
                statusIndicator.textContent = "Voice restarted!";
                setTimeout(() => {
                    statusIndicator.textContent = "";
                }, 2000);
            }, 1000);
        });

        // Send message on button click
        sendButton.addEventListener('click', () => {
            if (isRecording) {
                stopSpeechRecognition();
            } else {
                const message = textInput.value.trim();
                if (message !== "") {
                    addMessage(message, 'user');
                    textInput.value = '';
                    agentResponse(message);
                }
            }
        });

        // Send message on Enter key press
        textInput.addEventListener('keydown', (event) => {
            if (event.key === 'Enter') {
                if (isRecording) {
                    stopSpeechRecognition();
                } else {
                    const message = textInput.value.trim();
                    if (message !== "") {
                        addMessage(message, 'user');
                        textInput.value = '';
                        agentResponse(message);
                    }
                }
            }
        });

        // Focus on input when user starts typing
        document.addEventListener('keydown', (event) => {
            if (!isRecording && !textInput.disabled && 
                event.key.length === 1 && !event.ctrlKey && !event.altKey && !event.metaKey) {
                textInput.focus();
            }
        });

        // Initialize speech synthesis voices
        function initSpeechSynthesis() {
            // Function to log available voices and store them
            const checkVoices = () => {
                const voices = speechSynthesis.getVoices();
                console.log("Available voices:", voices.map(v => `${v.name} (${v.lang})`));
                
                // Try a test utterance to warm up the speech system
                const testUtterance = new SpeechSynthesisUtterance("Hello");
                testUtterance.volume = 0;  // Silent test
                testUtterance.onend = () => {
                    console.log("Speech synthesis system initialized");
                };
                speechSynthesis.speak(testUtterance);
            };
            
            // Chrome loads voices asynchronously
            if (speechSynthesis.onvoiceschanged !== undefined) {
                speechSynthesis.onvoiceschanged = checkVoices;
            }
            
            // Load voices immediately for other browsers
            checkVoices();
            
            // Safari on iOS sometimes needs a user interaction to initialize audio
            document.addEventListener('click', () => {
                const silentUtterance = new SpeechSynthesisUtterance(" ");
                silentUtterance.volume = 0;
                speechSynthesis.speak(silentUtterance);
            }, { once: true });
        }

        // --- Initialization ---
        function init() {
            // Initialize speech synthesis
            initSpeechSynthesis();
            
            setTimeout(() => {
                const welcomeMessage = "Hi there! I'm KiddoBot, your friendly talking buddy! I can understand your voice or you can type to me. What would you like to talk about today?";
                addMessage(welcomeMessage, 'agent');
                textInput.disabled = false;
                sendButton.disabled = false;
                
                // Delay speech recognition start until after welcome message is spoken
                setTimeout(() => {
                    startSpeechRecognition();
                }, 1000);
            }, 500);
        }

        init();
    </script>
</body>
</html>


